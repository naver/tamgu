## Res: 0x1.0d0e44bfeec9p -3

```python
println("Res:", res);
```

The output is: `Res: 0x1.0d0e44bfeec9p -3`.

## IV [6, 25, 26, 34]

```python
ivector iv = s.scan("%X");
println("IV", iv);
```

The output is: `IV [6, 25, 26, 34]`.

## VS ['0x1.0d0e44bfeec9p -3', '0x2.09p3', '0x3.456aebp -1']

```python
svector vs = s.scan("%X");
println("VS", vs);
```

The output is: `VS ['0x1.0d0e44bfeec9p -3', '0x2.09p3', '0x3.456aebp -1']` with 3 elements.

## VS ['0x1.0d0e44bfeec9p -3', '0x2.09p3']

```python
vs = s.scan("%X %X", " ");
println("VS", vs);
```

The output is: `VS ['0x1.0d0e44bfeec9p -3', '0x2.09p3']` with 2 elements.

```python
string reste;
fvector fv = s.scan("%X, %X", ",", false, reste);
println("FV", fv, reste);
```

The output is: `FV [0.131375, 16.2812] 0x3.456aebp -1 in here.`

To use treg string or not treg string?

In all the examples shown so far, `scan` takes a string as input, which is then compiled into a treg. However, it is possible to provide a treg instead of a string as the first parameter of `scan`. If the treg is given as an r string, it will be compiled at parse time instead of at execution time. This pre-compiling provides a slight advantage in using treg instead of strings at runtime.

Tokenization Rules

The methods `parenthetic`, `tags`, and `tokenization` all use an underlying set of tokenization rules, which can be modified through their `rules` parameter. The underlying set of rules can be loaded and modified to change or enrich the tokenization process using `_getdefaulttokenizerules`.

- `x-` means that the character should be recognized but not stored in the parsing string.
- `%.~..` means that all characters will be recognized except for those in the list after the tilde.

IMPORTANT: Do not add any spaces as they would be considered as a character to test.

Example:

```python
svector rules = _getdefaulttokenizerules();
rules.insert(55, "{%a %d}+ : {%a %d}+=0"); // aaa : bbb is now one token
rules.insert(55, "{%a %d}+.{%a %d}+=0"); // aaa.bbb is now one token
rules.insert(38, "->=0"); // -> is one token

string s = "this is a test.num -> x : 10";
// Without rules
v = s.tokenize(); // ['this', 'is', 'a', 'test', '.', 'num', '-', '>', 'x', ':', '10']
// With rules
v = s.tokenize(false, false, rules); // ['this', 'is', 'a', 'test.num', '->', 'x : 10']
```

`parenthetics()` or `parenthetics(string opening, string closing)`

Tamgu also provides a way to decipher parenthetic expressions such as:

```
((S (NP -SBJ Investors)
     (VP are
         (VP appealing
             (PP-CLR to
      (NP-1 the Securities))
             (S-CLR (NP -SBJ * -1)
     not
     (VP to
 (VP limit
     (NP (NP their access)
 (PP to
     (NP (NP information)
 (PP about
     (NP (NP stock purchases)
 (PP by
     (NP "insiders‚Äù)
 ))))))))))).))
```

Tamgu provides a method `parenthetics` which takes a structure like the one above and translates it into a vector.

```python
vector v = s.parenthetics(); // s contains a parenthetic expression as above
```

The second function enables the use of different opening or reading characters.

Example:

Tamgu can analyze the structure below:

```
<S <NP -SBJ They>
     <VP make
         <NP the argument>
  <PP-LOC in
  <NP <NP letters>
      <PP to
  <NP the agency>> > > > > .>
```

with the following instruction:

```python
vector v = s.parenthetics('<', '>');
```

`tags(string opening, string closing)`

`tags` is similar to the `parenthetics` method, except that instead of characters, it takes strings as input. It should not be used to parse XML output, use `xmldoc` instead.

```python
string s = "OPEN This is OPEN a nice OPEN example CLOSE CLOSE CLOSE";
vector v = s.tags('OPEN ', 'CLOSE ');
```

Output: `v = [['this', 'is', ['a', 'nice ', ['example']]]]`.